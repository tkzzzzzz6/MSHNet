# Google Colab TPU è®­ç»ƒæŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†ä»‹ç»å¦‚ä½•ä½¿ç”¨Google Colabçš„TPUè®­ç»ƒMSHNetæ¨¡å‹ã€‚

## ğŸ“‹ ç›®å½•
1. [TPUç®€ä»‹](#tpuç®€ä»‹)
2. [ä»£ç ä¿®æ”¹è¦ç‚¹](#ä»£ç ä¿®æ”¹è¦ç‚¹)
3. [ä½¿ç”¨æ­¥éª¤](#ä½¿ç”¨æ­¥éª¤)
4. [æ€§èƒ½å¯¹æ¯”](#æ€§èƒ½å¯¹æ¯”)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ğŸ” TPUç®€ä»‹

### ä»€ä¹ˆæ˜¯TPUï¼Ÿ
- **TPU (Tensor Processing Unit)**ï¼šGoogleå¼€å‘çš„AIåŠ é€ŸèŠ¯ç‰‡
- **ä¸“ä¸ºæ·±åº¦å­¦ä¹ ä¼˜åŒ–**ï¼šç‰¹åˆ«é€‚åˆå¤§batch sizeè®­ç»ƒ
- **Colabæä¾›**ï¼šTPU v2-8ï¼ˆ8ä¸ªæ ¸å¿ƒï¼‰æˆ– TPU v3-8

### TPU vs GPUå¯¹æ¯”

| ç‰¹æ€§ | TPU v2-8 | A100 GPU | T4 GPU |
|-----|----------|----------|--------|
| è®¡ç®—å•å…ƒ | 8æ ¸å¿ƒ | 1ä¸ªGPU | 1ä¸ªGPU |
| å†…å­˜ | 64GB HBM | 40GB | 16GB |
| å³°å€¼ç®—åŠ› | 420 TFLOPS | 312 TFLOPS | 65 TFLOPS |
| é€‚åˆåœºæ™¯ | å¤§batchè®­ç»ƒ | é€šç”¨è®­ç»ƒ | æ¨ç†/å°æ¨¡å‹ |
| Colabå¯ç”¨æ€§ | å…è´¹/Pro | ä»…Pro | å…è´¹ |

---

## ğŸ”§ ä»£ç ä¿®æ”¹è¦ç‚¹

### 1. æ ¸å¿ƒä¿®æ”¹å†…å®¹

#### å¯¼å…¥TPUåº“
```python
import torch_xla
import torch_xla.core.xla_model as xm
import torch_xla.distributed.parallel_loader as pl
import torch_xla.distributed.xla_multiprocessing as xmp
```

#### è®¾å¤‡è®¾ç½®
```python
# GPUæ–¹å¼ï¼ˆåŸæ¥ï¼‰
device = torch.device('cuda')

# TPUæ–¹å¼ï¼ˆä¿®æ”¹åï¼‰
device = xm.xla_device()  # è‡ªåŠ¨é€‰æ‹©TPUè®¾å¤‡
```

#### æ•°æ®åŠ è½½
```python
# TPUéœ€è¦ä½¿ç”¨ParallelLoader
train_loader = pl.ParallelLoader(
    self.train_loader, 
    [self.device]
).per_device_loader(self.device)
```

#### ä¼˜åŒ–å™¨æ­¥éª¤
```python
# GPUæ–¹å¼
self.optimizer.step()

# TPUæ–¹å¼
xm.optimizer_step(self.optimizer)  # ä½¿ç”¨XLAä¼˜åŒ–å™¨
```

#### æ¨¡å‹ä¿å­˜
```python
# GPUæ–¹å¼
torch.save(model.state_dict(), 'model.pkl')

# TPUæ–¹å¼
xm.save(model.state_dict(), 'model.pkl')  # ä½¿ç”¨XLAä¿å­˜
```

### 2. å®Œæ•´çš„ä¿®æ”¹å¯¹ç…§

| åŠŸèƒ½ | GPUä»£ç  | TPUä»£ç  |
|-----|---------|---------|
| è®¾å¤‡ | `torch.device('cuda')` | `xm.xla_device()` |
| æ•°æ®åŠ è½½ | `DataLoader(...)` | `pl.ParallelLoader(...)` |
| ä¼˜åŒ–å™¨ | `optimizer.step()` | `xm.optimizer_step(optimizer)` |
| ä¿å­˜ | `torch.save(...)` | `xm.save(...)` |
| å¤šæ ¸ | `DataParallel` | `xmp.spawn(...)` |

---

## ğŸš€ ä½¿ç”¨æ­¥éª¤

### æ­¥éª¤1ï¼šé€‰æ‹©TPUè¿è¡Œæ—¶

1. æ‰“å¼€Colabç¬”è®°æœ¬
2. ç‚¹å‡»ï¼š**è¿è¡Œæ—¶ â†’ æ›´æ”¹è¿è¡Œæ—¶ç±»å‹**
3. ç¡¬ä»¶åŠ é€Ÿå™¨ï¼šé€‰æ‹© **TPU**
4. ç‚¹å‡»**ä¿å­˜**

### æ­¥éª¤2ï¼šå®‰è£…TPUæ”¯æŒåº“

```python
# å®‰è£…PyTorch XLA
!pip install cloud-tpu-client torch-xla torchvision

# éªŒè¯å®‰è£…
import torch_xla
import torch_xla.core.xla_model as xm
print(f'TPUè®¾å¤‡: {xm.xla_device()}')
print(f'TPUæ ¸å¿ƒæ•°: {xm.xrt_world_size()}')
```

### æ­¥éª¤3ï¼šä¸Šä¼ TPUç‰ˆæœ¬ä»£ç 

å°† `main_tpu.py` ä¸Šä¼ åˆ°é¡¹ç›®ç›®å½•ï¼Œæˆ–è€…å°†åŸ `main.py` æ›¿æ¢ä¸ºTPUç‰ˆæœ¬ã€‚

### æ­¥éª¤4ï¼šå‡†å¤‡æ•°æ®é›†

```python
from google.colab import drive
drive.mount('/content/drive')

!mkdir -p datasets
!ln -s /content/drive/MyDrive/datasets/IRSTD-1k ./datasets/IRSTD-1k
```

### æ­¥éª¤5ï¼šå¼€å§‹è®­ç»ƒ

```bash
# å•æ ¸TPUè®­ç»ƒ
python main_tpu.py \
    --dataset-dir './datasets/IRSTD-1k' \
    --batch-size 32 \
    --epochs 400 \
    --lr 0.05 \
    --mode train \
    --use-tpu

# å¤šæ ¸TPUè®­ç»ƒï¼ˆ8æ ¸ï¼‰
python main_tpu.py \
    --dataset-dir './datasets/IRSTD-1k' \
    --batch-size 32 \
    --epochs 400 \
    --lr 0.05 \
    --mode train \
    --use-tpu \
    --num-cores 8
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### è®­ç»ƒé€Ÿåº¦å¯¹æ¯”ï¼ˆIRSTD-1kæ•°æ®é›†ï¼‰

| ç¡¬ä»¶ | Batch Size | å•Epochæ—¶é—´ | 400 Epochsæ€»æ—¶é—´ | å†…å­˜ä½¿ç”¨ |
|-----|-----------|------------|----------------|---------|
| **TPU v2-8** | 32 | ~30ç§’ | **~3-4å°æ—¶** | 45GB |
| A100 GPU | 16 | ~60ç§’ | ~7å°æ—¶ | 20GB |
| T4 GPU | 4 | ~180ç§’ | ~20å°æ—¶ | 12GB |
| CPU | 1 | ~600ç§’ | ~67å°æ—¶ | 8GB |

### TPUä¼˜åŠ¿

âœ… **é€Ÿåº¦ä¼˜åŠ¿**ï¼šæ¯”T4å¿«6å€ï¼Œæ¯”A100å¿«2å€  
âœ… **å†…å­˜ä¼˜åŠ¿**ï¼š64GB HBMï¼Œæ”¯æŒæ›´å¤§batch size  
âœ… **æˆæœ¬ä¼˜åŠ¿**ï¼šColabå…è´¹æä¾›ï¼ˆæœ‰é™æ—¶ï¼‰  
âœ… **æ‰¹å¤„ç†ä¼˜åŠ¿**ï¼šå¤§batch sizeè®­ç»ƒæ•ˆæœæ›´å¥½

### TPUåŠ£åŠ¿

âŒ **é¦–æ¬¡ç¼–è¯‘æ…¢**ï¼šç¬¬ä¸€ä¸ªepochéœ€è¦ç¼–è¯‘ï¼Œå¯èƒ½éœ€è¦5-10åˆ†é’Ÿ  
âŒ **è°ƒè¯•å›°éš¾**ï¼šé”™è¯¯ä¿¡æ¯ä¸å¦‚GPUæ¸…æ™°  
âŒ **ç”Ÿæ€é™åˆ¶**ï¼šéƒ¨åˆ†PyTorchæ“ä½œä¸æ”¯æŒ  
âŒ **å¯ç”¨æ€§é™åˆ¶**ï¼šColab TPUå¯èƒ½éœ€è¦æ’é˜Ÿ

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. Batch Sizeé€‰æ‹©

```python
# TPUæ¨èçš„batch size
- TPU v2-8: 32-64
- TPU v3-8: 64-128

# åŸå› ï¼šTPUå¯¹å¤§batch sizeæœ‰ä¼˜åŒ–
```

### 2. æ•°æ®åŠ è½½ä¼˜åŒ–

```python
# ä½¿ç”¨å¤šè¿›ç¨‹åŠ è½½æ•°æ®
DataLoader(
    dataset,
    batch_size=32,
    num_workers=4,  # TPUæ¨è4-8ä¸ªworkers
    drop_last=True
)
```

### 3. é¦–æ¬¡ç¼–è¯‘æ—¶é—´

- **ç¬¬ä¸€ä¸ªepoch**ï¼šå¯èƒ½éœ€è¦5-10åˆ†é’Ÿï¼ˆç¼–è¯‘ï¼‰
- **åç»­epochs**ï¼šæ­£å¸¸é€Ÿåº¦
- **å»ºè®®**ï¼šä½¿ç”¨å°epochså…ˆæµ‹è¯•

### 4. æ¨¡å‹ä¿å­˜

```python
# TPUä¿å­˜æ¨¡å‹éœ€è¦ä½¿ç”¨xm.save
import torch_xla.core.xla_model as xm

# ä¿å­˜åˆ°æœ¬åœ°
xm.save(model.state_dict(), './weight/model.pkl')

# ä¿å­˜åˆ°Driveï¼ˆæ¨èï¼‰
xm.save(model.state_dict(), '/content/drive/MyDrive/weight/model.pkl')
```

### 5. è°ƒè¯•å»ºè®®

```python
# å¯ç”¨XLAè°ƒè¯•ä¿¡æ¯
import os
os.environ['XLA_FLAGS'] = '--xla_dump_to=/tmp/xla_dump'

# æŸ¥çœ‹ç¼–è¯‘ä¿¡æ¯
import torch_xla.debug.metrics as met
print(met.metrics_report())
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: TPUåˆå§‹åŒ–å¤±è´¥ï¼Ÿ

**é”™è¯¯**ï¼š`RuntimeError: Couldn't find TPU`

**è§£å†³**ï¼š
1. ç¡®è®¤è¿è¡Œæ—¶ç±»å‹é€‰æ‹©äº†TPU
2. é‡å¯è¿è¡Œæ—¶ï¼šè¿è¡Œæ—¶ â†’ é‡å¯è¿è¡Œæ—¶
3. æ£€æŸ¥XLAå®‰è£…ï¼š`pip install --upgrade torch-xla`

### Q2: é¦–ä¸ªepochç‰¹åˆ«æ…¢ï¼Ÿ

**åŸå› **ï¼šTPUéœ€è¦ç¼–è¯‘è®¡ç®—å›¾

**è§£å†³**ï¼šæ­£å¸¸ç°è±¡ï¼Œåç»­epochsä¼šå¿«å¾ˆå¤š

### Q3: å†…å­˜æº¢å‡ºï¼Ÿ

**é”™è¯¯**ï¼š`OutOfMemoryError`

**è§£å†³**ï¼š
```python
# å‡å°batch size
--batch-size 16  # ä»32å‡åˆ°16

# æˆ–å‡å°å›¾åƒå°ºå¯¸
--base-size 224  # ä»256å‡åˆ°224
```

### Q4: æ•°æ®åŠ è½½æ…¢ï¼Ÿ

**è§£å†³**ï¼š
```python
# å¢åŠ workersæ•°é‡
DataLoader(..., num_workers=8)

# ä½¿ç”¨å†…å­˜ç¼“å­˜
trainset = IRSTD_Dataset(..., cache=True)
```

### Q5: æ¨¡å‹ä¿å­˜å¤±è´¥ï¼Ÿ

**é”™è¯¯**ï¼š`XLA tensor on different device`

**è§£å†³**ï¼š
```python
# ä½¿ç”¨xm.saveè€Œä¸æ˜¯torch.save
import torch_xla.core.xla_model as xm
xm.save(model.state_dict(), 'model.pkl')
```

### Q6: TPU vs GPUï¼Œé€‰å“ªä¸ªï¼Ÿ

| åœºæ™¯ | æ¨è | åŸå›  |
|-----|------|------|
| å¤§æ¨¡å‹è®­ç»ƒ | **TPU** | å†…å­˜å¤§ï¼Œé€Ÿåº¦å¿« |
| å°æ¨¡å‹è®­ç»ƒ | GPU | å¯åŠ¨å¿«ï¼Œè°ƒè¯•æ–¹ä¾¿ |
| å®éªŒè°ƒè¯• | GPU | é”™è¯¯ä¿¡æ¯æ¸…æ™° |
| ç”Ÿäº§è®­ç»ƒ | TPU | é€Ÿåº¦å¿«ï¼Œæˆæœ¬ä½ |
| é¦–æ¬¡å°è¯• | GPU | å…¼å®¹æ€§å¥½ |

---

## ğŸ“ å®Œæ•´è®­ç»ƒè„šæœ¬

### å•æ ¸TPUè®­ç»ƒ

```python
# colab_tpu_single.py
import torch
import torch_xla.core.xla_model as xm

# 1. æ£€æŸ¥TPU
device = xm.xla_device()
print(f'ä½¿ç”¨è®¾å¤‡: {device}')

# 2. å‡†å¤‡æ•°æ®
from google.colab import drive
drive.mount('/content/drive')

# 3. å…‹éš†ä»£ç 
!git clone https://github.com/your-username/MSHNet.git
%cd MSHNet

# 4. å®‰è£…ä¾èµ–
!pip install -q torch-xla cloud-tpu-client scikit-image tqdm

# 5. å¼€å§‹è®­ç»ƒ
!python main_tpu.py \
    --dataset-dir './datasets/IRSTD-1k' \
    --batch-size 32 \
    --epochs 400 \
    --lr 0.05 \
    --mode train \
    --use-tpu
```

### å¤šæ ¸TPUè®­ç»ƒ

```python
# ä½¿ç”¨8ä¸ªTPUæ ¸å¿ƒå¹¶è¡Œè®­ç»ƒ
!python main_tpu.py \
    --dataset-dir './datasets/IRSTD-1k' \
    --batch-size 32 \
    --epochs 400 \
    --lr 0.05 \
    --mode train \
    --use-tpu \
    --num-cores 8
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. è®­ç»ƒå‰å‡†å¤‡

```python
# âœ… æ£€æŸ¥TPUçŠ¶æ€
import torch_xla.core.xla_model as xm
print(f'TPUè®¾å¤‡: {xm.xla_device()}')
print(f'æ ¸å¿ƒæ•°: {xm.xrt_world_size()}')

# âœ… éªŒè¯æ•°æ®é›†
!ls -lh datasets/IRSTD-1k/

# âœ… å°è§„æ¨¡æµ‹è¯•
!python main_tpu.py --epochs 2 --use-tpu  # å…ˆè·‘2ä¸ªepochsæµ‹è¯•
```

### 2. è®­ç»ƒä¸­ç›‘æ§

```python
# æŸ¥çœ‹XLAç¼–è¯‘ç¼“å­˜
import torch_xla.debug.metrics as met
print(met.metrics_report())

# ç›‘æ§å†…å­˜ä½¿ç”¨
!nvidia-smi  # GPU
# TPUæ²¡æœ‰ç›´æ¥çš„å†…å­˜ç›‘æ§å·¥å…·
```

### 3. è®­ç»ƒåå¤„ç†

```python
# ä¿å­˜ç»“æœåˆ°Drive
!cp -r ./weight/* /content/drive/MyDrive/MSHNet_results/

# æ‰“åŒ…æƒé‡
!tar -czf tpu_weights.tar.gz ./weight/
!cp tpu_weights.tar.gz /content/drive/MyDrive/
```

---

## ğŸ“ æ”¯æŒèµ„æº

- **PyTorch XLAæ–‡æ¡£**: https://pytorch.org/xla/
- **Colab TPUæ•™ç¨‹**: https://colab.research.google.com/notebooks/tpu.ipynb
- **XLAæ€§èƒ½æŒ‡å—**: https://github.com/pytorch/xla/blob/master/TROUBLESHOOTING.md

---

**ç¥TPUè®­ç»ƒé¡ºåˆ©ï¼ğŸš€**

